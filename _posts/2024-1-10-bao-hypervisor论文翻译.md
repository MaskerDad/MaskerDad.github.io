---
title: bao-hypervisor论文翻译

date: 2024-1-10 17:00:00 +0800

categories: [bao-project学习]

tags: [hypervisor]

description: 
---

# Bao: A Lightweight Static Partitioning Hypervisor for Modern Multi-Core Embedded Systems

[Bao: A Lightweight Static Partitioning Hypervisor for Modern Multi-Core Embedded Systems (dagstuhl.de)](https://drops.dagstuhl.de/entities/document/10.4230/OASIcs.NG-RES.2020.3)

### 1. Abstract

鉴于目前现代嵌入式系统愈发强大的功能以及在其上集成混合安全关键系统的趋势，虚拟化技术受到了广泛的关注，以实现空间和时间的隔离。目前，成熟的虚拟机管理程序（如KVM和Xen）在设计时并未考虑嵌入式平台。针对嵌入平台的静态分区虚拟机管理程序，目前有 Jailhouse 和 Bao 两种方案。Jailhouse 似乎能够满足嵌入式平台的需要，但是其仍然依赖 Linux 来引导和管理其它虚拟机。本文介绍了 Bao，它基于 ARM-v8 和 RISC-V 平台，从大小、性能和中断延迟等角度进行评估，该方案产生的虚拟化开销较小。

### 2. Introduction

在汽车和工业控制等领域，日益增长的功能需求对嵌入式系统的计算能力提出了较高要求，同时也指导了嵌入式系统的升级迭代，从运行简单的裸机应用程序或实时操作系统的小型单核微控制器转变到强大的多核平台、具有复杂的存储层次结构、并且能够使用功能丰富的通用操作系统。同时，尺寸、重量、功率和成本的市场需要也指导了嵌入式系统的发展方向 —— 将多个子系统整合到同一个平台上，为了达到混合关键系统（MCS）的形式，需要平衡安全子系统和非安全子系统的隔离以及解决共享资源访问的冲突问题。

虚拟化是桌面和服务器中已经成熟的技术，是实现资源整合和集成的解决方案，能够保证虚拟机 (VM) 之间的隔离和故障控制。典型的面向服务器的虚拟机管理程序有 Xen [19, 47] 和 KVM [26, 12]，为了让它们适应嵌入式架构（主要是 ARM），学界已经做出了一些努力，并取得了相当大的成功。它们仍然不适用于混合关键系统的原因如下：

1. 鉴于系统的混合临界性质，逻辑隔离已被证明不足以满足严格的嵌入式约束和实时要求 [1]。
2. 这些嵌入式管理程序通常依赖于大型 GPOS（通常是 Linux）来引导、管理虚拟机或提供无数服务，例如设备仿真或虚拟网络 [4, 41]。从安全和安全的角度来看，这种依赖使系统可信计算库（TCB）过于臃肿，并拦截了安全启动机制中的信任链，总体上扩大了系统的攻击面[32]。由于此类操作系统的规模和单体架构，这种紧密耦合也阻碍了部署此类管理程序的系统的安全认证过程。

由 Siemens 开发的 Jailhouse [41] 静态分区管理程序架构最近在学术界和工业界的 MCS 中得到越来越多的采用。该架构利用硬件辅助虚拟化技术，采用最小软件层，静态划分所有平台资源并将每个资源专门分配给单个 VM。它假定不需要在 Guest 之间共享硬件资源。由于每个虚拟内核都静态绑定在单个物理 CPU 上，因此无需调度程序，也无需提供复杂的语义服务，进一步降低了尺寸和复杂性。尽管可能会妨碍有效的资源使用要求，但静态分区允许在隔离和实时方面提供更强的保证。尽管如此，Jailhouse 仍然依赖 Linux 来引导系统和管理它的 “cell”，仍存在与其他虚拟机管理程序相同的上述安全问题。

尽管静态分区方法提供了强大的 CPU 和内存隔离，这仍然不够，因为许多微架构资源（例如最后一级缓存、互连和内存控制器）仍然在分区之间共享。由此产生的争用导致缺乏时间隔离，损害性能和确定性 [3, 2]。此外，恶意虚拟机可以利用这一点通过增加共享资源的消耗来实施 DoS 攻击 [6]，或者通过隐式定时侧通道 [13] 间接访问其他虚拟机的数据。为了解决这个问题，诸如缓存分区（通过锁定或着色）或内存带宽预留之类的技术已经被提出并在操作系统和管理程序级别实现 [48,27,30,22]。

在本文中，本文介绍了 Bao，尽管遵循与 Jailhouse 相同的静态分区架构，但是 Bao 不依赖任何外部依赖（除了固件来执行低级平台管理）。此外，鉴于机制的简单性，它提供了对缓存着色的支持。Bao 最初针对的是 Armv8 架构，对 RISC-V 架构的实验性支持也可用。Bao 于 2019 年底开源。

### 3. Bao Hypervisor

Bao（来自汉语普通话“BAOHU”，意为“保护”）是一个面向安全的轻量级裸机管理程序。它专为 MCS 设计，重点关注故障控制和实时行为的隔离。它只包括一个最小的的特权软件，利用 ISA 虚拟化支持来实现静态分区管理程序架构：

* 资源在 VM 实例化时被静态分区和分配；
* 内存是使用两阶段翻译静态分配的；
* IO 仅用于传递；
* 虚拟中断直接映射到物理中断；
* 它实现了虚拟 CPU 到物理 CPU 的 1-1 映射，无需调度程序；
* 管理程序还提供了基于静态共享内存机制和通过超级调用触发的虚拟机间中断形式的异步通知的虚拟机间通信的基本机制；

![请添加图片描述](https://img-blog.csdnimg.cn/267ee05283ed49818774332bcef16856.png)

#### 3.1 Platform Support

Bao 目前支持 ARM-v8 架构。RISC-V 仅能够在仿真器上实现。截至撰写本文时，Bao 已移植到两个 ARMV8 平台：ZCU102/4 开发板上的 Xilinx 的 Zynq-US+ 和 Hikey 960 上的海思 Kirin 960。到目前为止，Bao 能够托管多个裸机应用程序，FreeRTOS 和 Erikav3 RTOS，以及 vanilla Linux 和 Android。

除了简单的串行驱动程序来执行基本的控制台输出，Bao 不依赖额外的设备驱动程序，并且只需要少量的平台相关描述（例如，CPU 数量、可用内存及其位置）即可移植到新平台。出于这个原因，Bao 依赖供应商提供的固件和通用引导加载程序来执行硬件初始化以及低级管理功能，并将管理程序和 Guest 映像加载到主内存。这显著减少了移植工作。

#### 3.2 Spatial and Temporal Isolation

按照隔离的要求，Bao 首先为每个物理 CPU 设置私有映射。使用递归页表映射技术，它避免了对物理内存的完整连续映射。这种方法通常不适用于管理多个地址空间，并且通常会导致页表查找的 TLB 占用空间过大。此外，管理程序代码页被标记为只读，并且通过将管理程序数据页配置为不可执行。关于时间，给定独占 CPU 分配，不需要调度程序，再加上由 Guest 直接管理的每个 CPU 计时器的可用性，允许完全的逻辑时间隔离。

尽管Bao拥有强大分区以及为最小化现有虚拟化开销所做的努力，但这还不足以保证确定性执行并满足关键 Guest 任务的最后期限。共享最后一级缓存 (LLC) 的争用仍然允许 Guest 分区之间的干扰。因此，鉴于其简单性，Bao 从一开始就实现了页面着色机制，从而实现了 LLC 缓存分区。然而，着色有几个缺点：

* 首先，它强制使用可用的最细粒度的页面大小，排除了使用超级页面的好处；
* 其次，因为它还划分了实际的物理地址空间，导致内存浪费和碎片；
* 关于着色的另一个问题是，由于 Bao 依赖引导加载程序加载访客镜像，这些镜像在内存中重新布局，它需要重新着色它们，即将加载的原始镜像中不符合颜色的页面复制到同意的页面分配给该特定 VM 的颜色，这将增加 VM 的启动时间。

可以单独为每个 VM 启用着色并选择每种颜色。

#### 3.3 I/O 和中断

Bao 在仅传递的 IO 配置中直接将外围设备分配给Guest。在支持的架构中，特别是 ARM，所有 IO 都是内存映射的，这是通过使用现有的内存映射机制和虚拟化支持提供的 2 阶段转换实现的。管理程序不验证给定外围设备的排他分配，这允许多个 Guest 共享它，尽管是以非监督方式。通用中断控制器 (GIC) 是 ARM 架构中的中断路由器和仲裁器。尽管它提供了一些中断虚拟化设施，但大多数可用的硬件平台都具有 GICv2 或 GICv3，它们不支持将中断直接传递到来宾分区。

所有中断都转发到管理程序，管理程序必须使用一组有限的挂起寄存器在 VM 中重新注入中断。除了导致不可避免的中断延迟增加的特权模式交叉开销之外，这还显着增加了中断管理代码的复杂性，尤其是在要模拟中断优先级等功能时。Bao 的实现确实遵循这条路径，因为许多 RTOS 使用中断优先级，有时甚至作为任务调度机制 [33, 40]。这个问题在最新版本的规范 GICv4 中得到了解决，它绕过了虚拟机管理程序来传递来宾中断 [12]。此外，有限的虚拟化支持要求来宾访问中央分配器必须使用陷阱和仿真来实现。根据访客访问分发服务器的频率和访问模式，这可能会显着降低性能。目前，Bao 仅支持 GICv2。

### 4. Evaluation

测试平台：Xilinx ZCU104，采用 Zynq-US+ SoC，配备运行频率为 1.2 GHz 的四核 Cortex-A53、每核 32K L1 数据和指令缓存以及共享的统一 1MB L2/LLC 缓存。

1. 代码大小和内存占用。
2. 启动时间、性能和中断延迟。将客户机本地执行（裸机）与托管执行（solo）和竞争下的托管执行（interf）进行比较，以评估运行多个客户机时产生的干扰。然后重复启用缓存分区（solo-col 和 interf-col）的托管场景。

本文在一个内核中执行目标测试 VM，而在添加干扰时，本文执行两个额外的裸机应用程序，每个应用程序都在一个单独的 VM 中，它们连续读写一个 512KiB 数组，步长等于缓存行大小（64 字节）。启用着色时，本文将一半 LLC (512 KiB) 分配给运行基准测试的 VM，将四分之一 (256 KiB) 分配给每个干扰裸机应用程序。管理程序代码和基准应用程序均使用带有 -O2 优化的 Arm GNU 工具链 8.2.1 版进行编译。

#### 4.1 Code Size and Memory Footprint

> 在本节中，评估源代码行 (SLoC) 数量，以及最终二进制文件的大小，然后分析运行时消耗来评估内存占用。

代码分为四个主要部分：arch 和 platform 目录包含特定于目标的功能，而 core 和 lib 目录分别具有主要的管理程序逻辑和实用程序（例如，字符串操作、格式化的打印代码）。每个目录的总 SLoC 和最终二进制大小如图所示。对于目标平台，总共包含 5.6 KSLoC，代码量反映了系统整体的低复杂度。

大多数代码是用 C 编写的，尽管低级初始化和上下文保存/恢复（异常进入和退出）等功能必须在汇编中实现。还可以看到，特定于体系结构的代码占总 SLoC 的大部分，这其中最大的部分是 GIC 虚拟化支持，占 Armv8 代码总量的近 1/3。在核心功能中，包括物理页面分配和页表管理的代码包含了 540 SLoC。静态分配的内存的大小约为 59 KiB。请注意，较大的 .bss 段大小主要是由于根页表的静态分配，最终要加载的二进制文件的总大小约为 43 KiB。

![请添加图片描述](https://img-blog.csdnimg.cn/d977e67b79794861a8e08947d3c13733.png)

接下来，本文评估在运行时分配的内存。

* 在启动时，每个 CPU 分配一个 28 KiB 的私有结构。此结构包括专用 CPU 堆栈和页表以及用于 CPU 间通信的公共页。对于这个四核平台，在启动时总共分配了 112 KiB。
* 在初始化期间，Bao 进一步分配 4 个页面 (16 KiB) 用于基于对象池的内部最小分配机制。
* 此外，对于每个 VM，虚拟机管理程序将为 VM 全局控制结构分配固定的 40 KiB，为每个虚拟 CPU 分配 8 KiB。每个 VM 的最大内存成本将是页表的数量，这首先取决于分配的内存和内存映射外围设备的大小，其次取决于是否启用了缓存着色。

如图显示了用于不同大小的已分配内存的页表数量。它突出了缓存着色机制在页表大小上引入的大开销。在所有 VM 初始化之后，除了使用上述对象池进行 CPU 间消息分配的小例外，不再进行内存分配。

![请添加图片描述](https://img-blog.csdnimg.cn/9abea637e4df437c8daac9b075bc150b.png)

#### 4.2 Boot Overhead

在本节中，本文评估 Bao 的启动时间开销（而不是系统的整体启动时间）。因此，在任何系统或虚拟机的引导阶段都没有进行任何优化。在这个平台中，完整的引导流程包括几个特定于平台的引导阶段：(i) BootRom 执行低级初始化并将第一阶段引导加载程序 (FSBL) 加载到片上存储器，然后 (ii) 加载 ATF 、包和 Guest 镜像到主存储器。接下来，(iii) FSBL 跳转到 ATF，然后 (iv) 处理对管理程序的控制。

对于本文的测量，本文使用了在 ATF 的早期阶段启用的 ARM 的自由运行架构计时器。因此，这些只是平台总启动时间的近似值，因为它们没有考虑之前的启动阶段。本文考虑两种情况：

* 运行 FreeRTOS 的小型 VM（117 KiB 映像大小和 32 MiB 内存）;
* 运行 Linux 的大型 VM（39 MiB 映像大小和 512 MiB 内存）。

对于每个 VM，本文考虑原生执行（裸机）场景，以及禁用和启用着色的托管执行（分别为单独和单色）。本文测量（i）管理程序初始化为从管理程序执行第一条指令到它处理对 VM 的控制的时间，以及（ii）总启动时间到来宾内部第一个应用程序开始的时间。本文强调 Bao 不会像其他嵌入式虚拟机管理程序那样执行 Guest 镜像加载这一事实。为此，它取决于引导加载程序。因此，镜像加载开销仅反映在总时间中。

![请添加图片描述](https://img-blog.csdnimg.cn/7a2164841ea645f0af8072d8ea086d2b.png)

如图显示了每种情况下 100 个样本的平均结果。在小型 VM 情况下，管理程序初始化开销最小（单独和 sol-col 场景分别为 6.5 和 9.2 毫秒）。与裸机方案相比，总启动时间分别增加了大约 13 (0.5%) 和 16 (0.6%) 毫秒。在运行 Linux 客户机的大型 VM 的情况下，Bao 分别需要大约 9.6 毫秒和 156.2 毫秒来初始化自身以及单独和单列情况下的 VM。与原生执行相比，在禁用和启用着色的情况下，总启动时间分别增加了大约 83 (0.7 %) ms 和 184 (2.4 %) ms。要强调的第一点是启用着色后管理程序初始化时间的大幅增加。这主要是因为 Bao 需要对引导加载程序布局的平面镜像进行着色，在此过程中将镜像的几段复制到颜色兼容的页面中。在大型客人镜像的情况下，这种情况会更加严重。其次，总启动时间的增加总是大于管理程序初始化时间。本文认为这是Guest初始化期间虚拟化开销的结果（例如 2 阶段转换和 GIC 分配器陷阱和仿真）。

#### 4.3 Performance Overhead and Interference

为了评估虚拟化性能开销和 VM 间干扰，本文采用了广泛使用的 MiBench Embedded Benchmark Suite [14]。MiBench 是一组 35 个基准测试，分为六个子集，每个子集都针对嵌入式市场的特定领域：汽车（和工业控制）、消费设备、办公自动化、网络、安全和电信。对于每个基准测试，MiBench 提供两个输入数据集（小型和大型）。本文将评估重点放在汽车子集上，因为这是 Bao 所针对的主要应用领域之一。它包括三个内存密集型基准，因此更容易受到缓存和内存争用 [7]（qsort、susan corners 和 susan edge）的干扰。

如图显示了汽车 MiBench 子集 1000 次运行的结果。对于每个基准，本文将结果显示为针对裸机执行情况的性能标准化，因此较高的值反映较差的性能。为了进一步调查和了解基准测试的行为，本文收集了有关 qsort 基准测试的内存访问指令的 L2 缓存未命中率、数据 TLB 未命中率和停顿周期率的信息。表显示了每个场景的小型和大型 qsort 基准测试的结果。

![请添加图片描述](https://img-blog.csdnimg.cn/ad5f1aa40a3946ef96b11c02a250eb63.png)

![请添加图片描述](https://img-blog.csdnimg.cn/44399ea0a53e42469d819d766b99728b.png)

分析图，可以在所有基准测试中或多或少地观察到相同的趋势。首先，观察托管执行会导致性能略有下降。这反映在表中，L2 高速缓存和数据 TLB 未命中率均略有增加，这反过来解释了内存访问停顿率的增加。正如预期的那样，这源于两阶段地址转换的虚拟化开销。其次，启用着色后，性能开销会进一步增加。表中的结果支持这一点，表显示所有指标都已显着增加。同样，正如预期的那样，这可以解释为只有一半的 L2 可用，并且着色排除了超级页面的使用，显着增加了 TLB 压力。在干扰情况下，性能会显着下降。表中的结果证实，这是由于可预见的二级缓存未命中爆炸式增长。

最后，本文可以看到通过着色进行缓存分区可以显着减少干扰。表显示，着色可以将 L2 未命中率完全降低到单独着色场景的水平。然而，回顾图，本文可以看到这种削减并没有反映在观察到的性能下降中，interf-col 中的性能下降仍然高于 solo-col 场景。这可以通过从 LLC（例如回写缓冲区、MSHR、互连、内存控制器）下游引入的仍然没有地址争用来解释，这反映在内存停顿周期率的差异中。正如预期的那样，basicmath 和 bitcount 受着色和干扰的影响要小得多，因为它们占用的内存要少得多。

图中的另一个明显趋势是，性能下降在基准的小数据集变化中总是更加明显。在比较小型和大型输入数据集变体时，本文看到，尽管表中 L2 缓存未命中率的增加相似，但小型变体经历了更大的性能下降。本文认为这可能是因为，鉴于小输入数据集基准的总执行时间较短，缓存未命中惩罚将对它们产生更大的影响。这个想法得到了表中观察到的内存访问停顿循环率的支持，这在小输入数据集的情况下会导致更高的百分比增加。

#### 4.4 Interrupt Latency

为了测量中断延迟并最大限度地减少与虚拟化无关的开销，本文制作了一个最小的裸机基准测试应用程序。此应用程序连续设置架构定时器以每 10 ms 触发一次中断。由于知道触发中断的时刻，本文将延迟计算为预期挂钟时间与它开始处理中断的实际时刻之间的差异。定时器的分辨率为 10 ns。下表总结了从每个场景的 1000 个样本中获得的结果。

![请添加图片描述](https://img-blog.csdnimg.cn/aab9dc3101854ce2b5b25beb40ff48e0.png)

在将本机与独立托管执行进行比较时，本文看到了显着的平均延迟和标准偏差分别增加了大约 430 ns 和 40 ns，最坏情况下的延迟增加了 1680 ns。这反映了由于陷阱和模式交叉成本以及中断管理和重新注入而导致的已预期 GIC 虚拟化开销。还可以看出，着色本身并不会显着影响平均中断延迟，但会略微增加最坏情况的延迟。

表中的结果也证实了缓存干扰和内存争用对中断延迟的预期不利影响，尤其是在最坏的情况下。平均延迟增加 ≈12 ns，标准偏差增加 ≈41 ns，最坏情况下增加 1160 ns。启用着色对平均延迟没有明显的好处，实际上会增加标准偏差和最坏情况的延迟。本文认为这是因为，在这种情况下，相关的干扰实际上不是虚拟机之间，而是干扰客户和虚拟机管理程序本身之间，而虚拟机管理程序本身并没有着色。

### 5. On the Road

Bao 的发展还处于萌芽阶段。在撰写本文时，正在扩展对 Arm 架构的支持，包括 SMMU（Arm 的 IOMMU）和最新的 GIC 版本（v3 和 v4）。我们还将系统移植到一系列不同的平台，包括 NVIDIA 的 Jetson TX2 和 NXP 的 i.MX 8。此外，鉴于代码库较小，本文计划进行整体重构以遵守 MISRA C 编码指南。

Bao 从一开始就实现了缓存着色，作为微架构分区和隔离的第一线。我们的目标是实现其他最先进的分区机制（例如内存节流），并对虚拟机管理程序镜像本身进行着色，因为本文已经验证虚拟机之间或虚拟机与虚拟机管理程序之间仍然存在争用问题。但是，本文认为这些问题应该得到专用硬件机制的支持，以不增加代码复杂性和大小以及最小化开销。事实上，ARM 已经在 Armv8.4 上提出了内存系统资源分区和监控 (MPAM) [25] 扩展。MPAM 为共享缓存、互连和内存带宽分区提供硬件支持。不幸的是，迄今为止还没有具有这些扩展功能的硬件可用。本文计划使用 ARM 基础平台模型实现对 MPAM 的支持，以便本文可以在它可用时尽快在真实硬件上对其进行测试。

最后，由于 Bao 也是一个面向安全的虚拟机管理程序，因此可信执行环境 (TEE) 支持也在路上。通常，ARM TEE 以 TrustZone 技术为基础，这是一组安全的硬件扩展，可将平台分成一个安全和正常的世界 [37]。TEE 内核和应用程序在安全端运行，而其他一切（包括管理程序）在正常世界中执行。目前，TrustZone 不支持多个隔离的 TEE。已经提出了几种安全世界虚拟化方法 [18,10,24]，最近，Arm 在 Armv8.4 上增加了安全世界虚拟机管理程序支持。然而，基于 TrustZone 的 TEE 的双世界方法已被证明存在缺陷 [9]。此外，本文认为运行额外的安全管理程序会不必要地增加复杂性，并且安全世界应该只用于封装绝对安全原语（例如安全启动、证明、身份验证、密钥管理）。Bao 的方法将考虑到这一点，并使用现有的虚拟化机制，无需额外的调度逻辑，将允许在正常世界中的单个硬件分区内有多个 VM。TEE 将部署在辅助 VM 上，并且仅根据Host/Guest的请求执行。这种方法的另一个优点是它可以跨架构移植和扩展，而不是特定于 ARM。
